ä¸‹é¢æ˜¯ä¸€ä»½å¯ä»¥ç›´æ¥æ”¾è¿› alerting/service/receiver/README.md çš„ã€Œè½åœ°å®æ–½è®¡åˆ’ã€ã€‚å®ƒæŠŠ Prometheus â†’ Alertmanager â†’ï¼ˆPOST JSONï¼‰â†’ /receiver çš„æ•°æ®æ¥æ”¶ã€è§£ææ ¡éªŒã€ä»¥åŠç»“æ„åŒ–æ’å…¥ PostgreSQL çš„æ¯ä¸€æ­¥æ‹†æ¸…æ¥šï¼Œå¹¶æŒ‰ä½ çš„ç›®å½•ç»™å‡ºéœ€è¦æ–°å»ºçš„æ–‡ä»¶ä¸ä»£ç éª¨æ¶ã€‚

â¸»

ğŸ§­ ç«¯åˆ°ç«¯éªŒè¯ï¼ˆDocker Postgres + æœ¬æœåŠ¡ï¼‰

ä»¥ä¸‹æ­¥éª¤æ¼”ç¤ºä» Alertmanager Webhook åˆ°æ•°æ®åº“è½åº“çš„å®Œæ•´é“¾è·¯éªŒè¯ï¼š

1) å¯åŠ¨ Postgresï¼ˆDockerï¼‰

```bash
docker run --name zeroops-pg \
  -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=postgres -e POSTGRES_DB=zeroops \
  -p 5432:5432 -d postgres:16
```

2) åˆå§‹åŒ–å‘Šè­¦ç›¸å…³è¡¨
è¿è¡Œé›†æˆæµ‹è¯•ï¼ˆéœ€ Postgres å®ä¾‹ä¸ `-tags=integration`ï¼‰å¯éªŒè¯æ’å…¥æˆåŠŸï¼š
```bash
go test ./internal/alerting/service/receiver -tags=integration -run TestPgDAO_InsertAlertIssue -v
```

3) é…ç½®ç¯å¢ƒå˜é‡å¹¶å¯åŠ¨æœåŠ¡ï¼ˆå¦å¼€ä¸€ä¸ª shell åå°è¿è¡Œï¼‰

```bash
export DB_HOST=localhost DB_PORT=5432 DB_USER=postgres DB_PASSWORD=postgres DB_NAME=zeroops DB_SSLMODE=disable
export ALERT_WEBHOOK_BASIC_USER=alert ALERT_WEBHOOK_BASIC_PASS=REDACTED
nohup go run ./cmd/zeroops -- 1>/tmp/zeroops.out 2>&1 &
```

4) ç”¨ curl æ¨¡æ‹Ÿ Alertmanager å‘é€ firing äº‹ä»¶

```bash
curl -u alert:REDACTED -H 'Content-Type: application/json' \
  -X POST http://localhost:8080/v1/integrations/alertmanager/webhook -d '{
  "receiver":"our-webhook",
  "status":"firing",
  "alerts":[{
    "status":"firing",
    "labels":{"alertname":"HighRequestLatency","service":"serviceA","severity":"P1","idc":"yzh"},
    "annotations":{"summary":"p95 latency over threshold","description":"apitime p95 > 450ms"},
    "startsAt":"2025-05-05T11:00:00Z",
    "endsAt":"0001-01-01T00:00:00Z",
    "generatorURL":"http://prometheus/graph?g0.expr=...",
    "fingerprint":"3b1b7f4e8f0e"
  }],
  "groupLabels":{"alertname":"HighRequestLatency"},
  "commonLabels":{"service":"serviceA","severity":"P1"},
  "version":"4"
}'
```

5) åœ¨æ•°æ®åº“ä¸­éªŒè¯ï¼ˆåº”çœ‹åˆ°ä¸€è¡Œ Open/P1/InProcessing ä¸”æ ‡é¢˜åŒ¹é…çš„è®°å½•ï¼‰

```bash
docker exec -i zeroops-pg psql -U postgres -d zeroops -c \
  "SELECT id,state,level,alert_state,title,alert_since FROM alert_issues WHERE title='p95 latency over threshold' AND alert_since='2025-05-05 11:00:00'::timestamp;"
```
```bash
# æ›´æ˜“è¯»ï¼ˆæ ¼å¼åŒ– JSONï¼‰labels
docker exec -i zeroops-pg psql -U postgres -d zeroops -c \
   "SELECT jsonb_pretty(labels::jsonb) AS label FROM alert_issues WHERE title='p95 latency over threshold' AND alert_since='2025-05-05 11:00:00'::timestamp;"

```

6)ï¼ˆå¯é€‰ï¼‰è¿è¡Œå¸¦é›†æˆæ ‡ç­¾çš„æœ€å° DAO æµ‹è¯•

```bash
DB_HOST=localhost DB_PORT=5432 DB_USER=postgres DB_PASSWORD=postgres DB_NAME=zeroops DB_SSLMODE=disable \
go test ./internal/alerting/service/receiver -tags=integration -run TestPgDAO_InsertAlertIssue -v
```


receiver/ â€” ä» Alertmanager Webhook åˆ° alert_issues å…¥åº“çš„å®æ–½è®¡åˆ’

ç›®æ ‡ï¼šå½“ Alertmanager å‘æœ¬æœåŠ¡å‘èµ· POST JSON æ—¶ï¼Œç¬¬ä¸€æ¬¡åˆ›å»ºå‘Šè­¦è®°å½•å¹¶è½è¡¨ alert_issuesï¼Œå­—æ®µè§„åˆ™ï¼š
	â€¢	state é»˜è®¤ Open
	â€¢	alertState é»˜è®¤ InProcessing
	â€¢	å…¶ä½™å­—æ®µæŒ‰ webhook è¯·æ±‚ä½“è§£æã€æ ¡éªŒåå†™å…¥

æœ¬è®¡åˆ’ä»…è¦†ç›–ã€Œé¦–æ¬¡åˆ›å»ºã€é€»è¾‘ï¼›resolvedï¼ˆæ¢å¤ï¼‰æ›´æ–°é€»è¾‘å¯åœ¨åç»­è¡¥å……ï¼ˆä¾‹å¦‚åˆ‡æ¢ state=Closedã€alertState=Restoredï¼‰ã€‚

â¸»

â‘  ç›®å½•ä¸æ–‡ä»¶å‡†å¤‡

åœ¨ alerting/service/receiver/ ä¸‹æ–°å»ºå¦‚ä¸‹æ–‡ä»¶ï¼ˆæŒ‰æ¨¡å—èŒè´£åˆ’åˆ†ï¼‰ï¼š

alerting/
â””â”€ service/
   â””â”€ receiver/
      â”œâ”€ README.md                 # â† å°±æ”¾æœ¬æ–‡æ¡£
      â”œâ”€ router.go                 # æ³¨å†Œè·¯ç”±ï¼šPOST /v1/integrations/alertmanager/webhook
      â”œâ”€ handler.go                # HTTP å…¥å£ï¼Œæ¥æ”¶ä¸æ•´ä½“ç¼–æ’
      â”œâ”€ dto.go                    # å…¥å‚ï¼ˆAlertmanager Webhookï¼‰ä¸å†…éƒ¨ DTO å®šä¹‰
      â”œâ”€ validator.go              # å­—æ®µæ ¡éªŒï¼ˆå¿…å¡«/æšä¸¾/æ—¶é—´æ ¼å¼ç­‰ï¼‰
      â”œâ”€ mapper.go                 # æ˜ å°„ï¼šAM payload â†’ alert_issues è¡Œè®°å½•
      â”œâ”€ dao.go                    # DB è®¿é—®ï¼ˆInsert/Query/äº‹åŠ¡/é‡è¯•ï¼‰
      â”œâ”€ idempotency.go            # å¹‚ç­‰é”®ç”Ÿæˆä¸â€œå·²å¤„ç†â€å¿«é€Ÿåˆ¤æ–­ï¼ˆåº”ç”¨å±‚ï¼‰
      â””â”€ errors.go                 # ç»Ÿä¸€é”™è¯¯å®šä¹‰ï¼ˆå‚æ•°é”™è¯¯/DBé”™è¯¯ç­‰ï¼‰

è‹¥ä½ çš„ DB è¿æ¥å°è£…åœ¨ alerting/database/ï¼Œdao.go é‡Œç›´æ¥å¼•å…¥å…¬ç”¨çš„ db å®¢æˆ·ç«¯å³å¯ã€‚

â¸»

â‘¡ è·¯ç”±ä¸å…¥å£

router.go

// package receiver
func RegisterReceiverRoutes(r *gin.Engine, h *Handler) {
    r.POST("/v1/integrations/alertmanager/webhook", h.AlertmanagerWebhook)
}

handler.go

type Handler struct {
    dao *DAO
}

func NewHandler(dao *DAO) *Handler { return &Handler{dao: dao} }

func (h *Handler) AlertmanagerWebhook(c *gin.Context) {
    var req AMWebhook // dto.go ä¸­å®šä¹‰çš„ Alertmanager è¯·æ±‚ä½“ç»“æ„
    if err := c.BindJSON(&req); err != nil {
        c.JSON(http.StatusBadRequest, gin.H{"ok": false, "error": "invalid JSON"})
        return
    }

    // 1) åŸºæœ¬å­—æ®µæ ¡éªŒ
    if err := ValidateAMWebhook(&req); err != nil {
        c.JSON(http.StatusBadRequest, gin.H{"ok": false, "error": err.Error()})
        return
    }

    // 2) ä»…å¤„ç† status == "firing" çš„é¦–æ¬¡åˆ›å»º
    if strings.ToLower(req.Status) != "firing" {
        c.JSON(http.StatusOK, gin.H{"ok": true, "msg": "ignored (not firing)"})
        return
    }

    // 3) å¯¹æ¯æ¡ alert åšè½åº“ï¼ˆå¯èƒ½ä¸€æ‰¹å¤šä¸ªï¼‰
    //    å¹‚ç­‰é”®å»ºè®®ï¼šfingerprint + startsAtï¼ˆåŒä¸€å‘Šè­¦èµ·å§‹æ—¶é—´è§†ä¸ºåŒä¸€äº‹ä»¶ï¼‰
    created := 0
    for _, a := range req.Alerts {
        key := BuildIdempotencyKey(a)         // idempotency.go
        if AlreadySeen(key) {                 // åº”ç”¨å±‚çŸ­è·¯ï¼ˆå¯é€‰ï¼‰
            continue
        }

        row, mapErr := MapToAlertIssueRow(&req, &a) // mapper.go â†’ ç»„è£… alert_issues è¡Œ
        if mapErr != nil {
            // å•æ¡å¤±è´¥ä¸å½±å“å…¶å®ƒï¼Œè®°å½•æ—¥å¿—å³å¯
            continue
        }

        // 4) æ’å…¥ DBï¼ˆç¬¬ä¸€æ¬¡åˆ›å»ºå¼ºåˆ¶ state=Open, alertState=InProcessingï¼‰
        if err := h.dao.InsertAlertIssue(c, row); err != nil {
            // è‹¥å”¯ä¸€çº¦æŸå†²çª/ç½‘ç»œæŠ–åŠ¨ç­‰ï¼Œè®°å½•åç»§ç»­
            continue
        }
        MarkSeen(key) // è®°å¿†å¹‚ç­‰é”®
        created++
    }

    c.JSON(http.StatusOK, gin.H{"ok": true, "created": created})
}


â¸»

â‘¢ å…¥å‚ DTO ä¸å†…éƒ¨ç»“æ„

dto.goï¼ˆAlertmanager Webhook è½½è· + å†…éƒ¨æ’å…¥ç»“æ„ï¼‰

type KV map[string]string

// æ¥è‡ª Alertmanager çš„å•æ¡å‘Šè­¦
type AMAlert struct {
    Status       string    `json:"status"`       // firing|resolved
    Labels       KV        `json:"labels"`       // åŒ…å« alertnameã€serviceã€severity ç­‰
    Annotations  KV        `json:"annotations"`  // åŒ…å« summary/description ç­‰
    StartsAt     time.Time `json:"startsAt"`
    EndsAt       time.Time `json:"endsAt"`
    GeneratorURL string    `json:"generatorURL"`
    Fingerprint  string    `json:"fingerprint"`  // ç”¨äºå¹‚ç­‰
}

// Webhook æ ¹å¯¹è±¡
type AMWebhook struct {
    Receiver          string    `json:"receiver"`
    Status            string    `json:"status"`            // firing|resolved
    Alerts            []AMAlert `json:"alerts"`
    GroupLabels       KV        `json:"groupLabels"`
    CommonLabels      KV        `json:"commonLabels"`
    CommonAnnotations KV        `json:"commonAnnotations"`
    ExternalURL       string    `json:"externalURL"`
    Version           string    `json:"version"`
    GroupKey          string    `json:"groupKey"`
}

// å‡†å¤‡æ’å…¥ alert_issues çš„è¡Œï¼ˆä¸è¡¨å­—æ®µä¸€ä¸€å¯¹åº”ï¼‰
type AlertIssueRow struct {
    ID         string          // uuid
    State      string          // enum: Open/Closed ï¼ˆé¦–æ¬¡å›ºå®š Openï¼‰
    Level      string          // varchar(32): P0/P1/P2/Warning
    AlertState string          // enum: InProcessing/Restored/AutoRestoredï¼ˆé¦–æ¬¡å›ºå®š InProcessingï¼‰
    Title      string          // varchar(255)
    LabelJSON  json.RawMessage // json: æ ‡å‡†åŒ–åçš„ [{key,value}]
    AlertSince time.Time       // timestamp: ç”¨ StartsAt
}


â¸»

â‘£ å­—æ®µæ ¡éªŒï¼ˆvalidatorï¼‰

validator.go

func ValidateAMWebhook(w *AMWebhook) error {
    if w == nil { return errors.New("nil payload") }
    if len(w.Alerts) == 0 { return errors.New("alerts empty") }
    // å¯åŠ å¤§å°é™åˆ¶ï¼šlen(alerts) <= Nï¼›é˜²å·¨é‡ payload
    for i := range w.Alerts {
        a := &w.Alerts[i]
        if a.StartsAt.IsZero() { return fmt.Errorf("alerts[%d].startsAt empty", i) }
        // å…è®¸ç©º annotations.summaryï¼Œä½†åç»­ä¼šç”¨å›é€€è§„åˆ™ç”Ÿæˆ title
        if a.Status == "" { a.Status = "firing" } // å®¹é”™
    }
    return nil
}

var allowedLevels = map[string]bool{"P0":true,"P1":true,"P2":true,"Warning":true}

func NormalizeLevel(sev string) string {
    s := strings.ToUpper(strings.TrimSpace(sev))
    if allowedLevels[s] { return s }
    // è‹¥ä¸ºç©º/ä¸åˆæ³•ï¼Œå¯è®¾ç½®é»˜è®¤æˆ–äº¤ç»™ severity æ¨¡å—å†è¯„ä¼°
    return "Warning"
}


â¸»

â‘¤ æ˜ å°„è§„åˆ™ï¼ˆmapperï¼‰

ç›®æ ‡ï¼šå°† Alertmanager çš„å•æ¡ AMAlert â†’ AlertIssueRowã€‚
	â€¢	idï¼šuuid.NewString()
	â€¢	stateï¼šOpenï¼ˆé¦–æ¬¡åˆ›å»ºå¼ºåˆ¶ï¼‰
	â€¢	alertStateï¼šInProcessingï¼ˆé¦–æ¬¡åˆ›å»ºå¼ºåˆ¶ï¼‰
	â€¢	levelï¼šNormalizeLevel(alert.Labels["severity"])
	â€¢	titleï¼šä¼˜å…ˆ annotations.summaryï¼Œå¦åˆ™æ‹¼ï¼š{idc} {service} {alertname} ...
	â€¢	labelï¼šæŠŠ labels å±•å¹³æˆ [{key,value}]ï¼ˆé¢å¤–åŠ ä¸Šä¸€äº›å…³é”®æ¥æºä¿¡æ¯ï¼šam_fingerprintã€generatorURLã€groupKeyï¼‰
	â€¢	alertSinceï¼šStartsAtï¼ˆç»Ÿä¸€è½¬ UTCï¼‰

mapper.go

func MapToAlertIssueRow(w *AMWebhook, a *AMAlert) (*AlertIssueRow, error) {
    // 1) Title
    title := strings.TrimSpace(a.Annotations["summary"])
    if title == "" {
        // fallbackï¼šå°½é‡ä¿¡æ¯é‡å¤§ä¸”â‰¤255
        title = fmt.Sprintf("%s %s %s",
            a.Labels["idc"], a.Labels["service"], a.Labels["alertname"])
        title = strings.TrimSpace(title)
        if title == "" { title = "Alert from Alertmanager" }
    }
    if len(title) > 255 { title = title[:255] }

    // 2) Level
    level := NormalizeLevel(a.Labels["severity"])

    // 3) Labels â†’ []{key,value}
    //    é™„åŠ æŒ‡çº¹ç­‰æ–¹ä¾¿åç»­æŸ¥è¯¢/å¯¹è´¦
    flat := make([]map[string]string, 0, len(a.Labels)+3)
    for k, v := range a.Labels {
        flat = append(flat, map[string]string{"key": k, "value": v})
    }
    if a.Fingerprint != "" {
        flat = append(flat, map[string]string{"key": "am_fingerprint", "value": a.Fingerprint})
    }
    if g := strings.TrimSpace(a.GeneratorURL); g != "" {
        flat = append(flat, map[string]string{"key": "generatorURL", "value": g})
    }
    if w.GroupKey != "" {
        flat = append(flat, map[string]string{"key": "groupKey", "value": w.GroupKey})
    }
    b, _ := json.Marshal(flat)

    // 4) Row
    return &AlertIssueRow{
        ID:         uuid.NewString(),
        State:      "Open",
        AlertState: "InProcessing",
        Level:      level,
        Title:      title,
        LabelJSON:  b,
        AlertSince: a.StartsAt.UTC(), // å»ºè®®ç»Ÿä¸€ UTC
    }, nil
}


â¸»

â‘¥ å¹‚ç­‰ï¼ˆidempotencyï¼‰

è™½ç„¶æœ¬æ­¥éª¤ä¸»è¦æè¿°â€œé¦–æ¬¡åˆ›å»ºâ€ï¼Œä½†ä¸ºäº†é¿å…é‡å¤æ’å…¥ï¼Œå»ºè®®å¼•å…¥åº”ç”¨å±‚å¹‚ç­‰ï¼ˆæ— é¡»æ”¹è¡¨ç»“æ„ï¼‰ï¼š

idempotency.go

func BuildIdempotencyKey(a AMAlert) string {
    return a.Fingerprint + "|" + a.StartsAt.UTC().Format(time.RFC3339Nano)
}

// å¯ä»¥ç”¨å†…å­˜ LRU/Redisï¼›æˆ–å…¥åº“å‰å…ˆæŒ‰ (am_fingerprint + startsAt) æŸ¥è¯¢æ˜¯å¦å­˜åœ¨
func AlreadySeen(key string) bool { /* TODO */ return false }
func MarkSeen(key string)         { /* TODO */ }

è‹¥åç»­å…è®¸è°ƒæ•´è¡¨ç»“æ„ï¼Œå¯æŠŠ am_fingerprint å•åˆ—åŒ–å¹¶ä¸ alertSince ç»„æˆå”¯ä¸€ç´¢å¼•ï¼Œå¹‚ç­‰æ›´ç¨³ã€‚

â¸»

â‘¦ æ•°æ®è®¿é—®ï¼ˆDAOï¼‰

dao.goï¼ˆç¤ºä¾‹ä½¿ç”¨ pgx / database/sqlï¼Œé‡ç‚¹æ˜¯å‚æ•°åŒ–ä¸äº‹åŠ¡ï¼‰

type DAO struct{ DB *pgxpool.Pool }

func (d *DAO) InsertAlertIssue(ctx context.Context, r *AlertIssueRow) error {
    const q = `
    INSERT INTO alert_issues
        (id, state, level, alertState, title, label, alertSince)
    VALUES
        ($1, $2, $3, $4, $5, $6, $7)
    `
    _, err := d.DB.Exec(ctx, q,
        r.ID, r.State, r.Level, r.AlertState, r.Title, r.LabelJSON, r.AlertSince)
    return err
}

æ³¨æ„ï¼š
	â€¢	label åˆ—ç±»å‹ä¸º jsonï¼ˆå»ºè®®å®é™…ä½¿ç”¨ jsonbï¼‰ï¼Œæ­¤å¤„ç”¨ json.RawMessage å‚æ•°åŒ–å†™å…¥å³å¯ã€‚
	â€¢	ä½¿ç”¨ Exec/Prepare éƒ½å¯ï¼Œç¡®ä¿ä¸æ‹¼æ¥å­—ç¬¦ä¸²ï¼Œé˜²æ³¨å…¥ã€‚
	â€¢	ç”Ÿäº§å»ºè®®å¢åŠ ï¼šé‡è¯•ç­–ç•¥ã€æ’å…¥è€—æ—¶ç›‘æ§ã€é”™è¯¯åˆ†çº§ï¼ˆå”¯ä¸€å†²çª vs ç½‘ç»œæŠ–åŠ¨ï¼‰ã€‚

â¸»

â‘§ æˆåŠŸ/å¤±è´¥è¿”å›ä¸æ—¥å¿—
	â€¢	è¿”å›ï¼šç»Ÿä¸€ 200 {"ok": true, "created": <n>}ï¼Œå³ä½¿ä¸ªåˆ«è®°å½•å¤±è´¥ä¹Ÿå¿«é€Ÿè¿”å›ï¼Œé¿å… Alertmanager é˜»å¡é‡è¯•ã€‚
	â€¢	æ—¥å¿—ï¼šæŒ‰ alertname/service/severity/fingerprint æ‰“ç‚¹ï¼›é”™è¯¯åŒ…å« SQLSTATE/å †æ ˆï¼›ç»Ÿè®¡æ¥æ”¶/è§£æ/æ’å…¥è€—æ—¶åˆ†ä½ã€‚

â¸»

â‘¨ æœ€å°è”è°ƒï¼ˆäººå·¥æ¨¡æ‹Ÿï¼‰

firing æ¨¡æ‹Ÿï¼š

curl -X POST http://localhost:8080/v1/integrations/alertmanager/webhook \
  -H 'Content-Type: application/json' \
  -d '{
    "receiver":"our-webhook",
    "status":"firing",
    "alerts":[
      {
        "status":"firing",
        "labels":{"alertname":"HighRequestLatency","service":"serviceA","severity":"P1","idc":"yzh"},
        "annotations":{"summary":"p95 latency over threshold","description":"apitime p95 > 450ms"},
        "startsAt":"2025-05-05T11:00:00Z",
        "endsAt":"0001-01-01T00:00:00Z",
        "generatorURL":"http://prometheus/graph?g0.expr=...",
        "fingerprint":"3b1b7f4e8f0e"
      }
    ],
    "groupLabels":{"alertname":"HighRequestLatency"},
    "commonLabels":{"service":"serviceA","severity":"P1"},
    "version":"4"
  }'

å…¥åº“åï¼Œalert_issues é‡Œåº”çœ‹åˆ°ï¼š
	â€¢	state=Open
	â€¢	alertState=InProcessing
	â€¢	level=P1
	â€¢	title="p95 latency over threshold"
	â€¢	label ä¸­åŒ…å« am_fingerprint/generatorURL/groupKey/...
	â€¢	alertSince=2025-05-05 11:00:00+00

â¸»